# Disentangled Multi-Modal Music Clustering using Hybrid Beta-VAE

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WMch9Rr9Okq06HAz6Lit-hyAlC35vQ5O?usp=sharing)
[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/rummanahmedprodhan/2-gtzan-benchmark-clustering)
[![Project Report](https://img.shields.io/badge/PDF-Read%20Report-red)](https://drive.google.com/file/d/1xP4n4tslrkjtkb3aqOaloO0rq93gpKdO/view?usp=sharing)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“Œ Project Overview
This repository contains the implementation of a **Hybrid Beta-Variational Autoencoder (Beta-VAE)** for unsupervised music clustering. The project addresses the challenge of cross-cultural music analysis by fusing **Convolutional Spectral Features (Audio)** with **Semantic Lyric Embeddings (Text)**.

By imposing a heavy KL-divergence penalty ($\beta=4.0$), the model successfully disentangles "Language" (from lyrics) and "Genre" (from audio) into orthogonal axes in the latent space.

* **Course:** Neural Networks
* **Track:** Hard Task (Conditional/Beta-VAE & Multi-modal Clustering)
* **Author:** Rumman Ahmed Prodhan

## ğŸš€ Key Features
* **Multi-Modal Fusion:** Integrates Log-Mel Spectrograms (via CNN) and Sentence-BERT embeddings.
* **Beta-VAE Architecture:** Uses $\beta=4.0$ to enforce statistical independence in the latent space.
* **Custom Dataset (HBLM-100):** A curated dataset of 100 Bangla and English tracks for cross-cultural evaluation.
* **State-of-the-Art Metrics:** Achieved **ARI=1.0** and **NMI=1.0** on language separation tasks.
* **Benchmarked:** Validated audio encoders against the standard GTZAN genre dataset.

## ğŸ’» Run the Experiments
The project is divided into two major experiments. You can run them directly in the cloud using the links below.

### **1. Main Experiment: Cross-Cultural Clustering (HBLM-100)**
Disentangling language from genre using the Fusion Encoder on the custom dataset.
<br>
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WMch9Rr9Okq06HAz6Lit-hyAlC35vQ5O?usp=sharing)

### **2. Benchmark Experiment: Genre Classification (GTZAN)**
Validating the audio encoder on standard genre classification tasks using Kaggle GPUs.
<br>
[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/rummanahmedprodhan/2-gtzan-benchmark-clustering)

<br>

## ğŸ“Š Results Summary

| Dataset | Method | ARI | NMI | Silhouette | Purity | CH Index |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **HBLM-100** | **Hybrid Beta-VAE** | **1.00** | **1.00** | **0.21** | **1.00** | **238.6** |
| HBLM-100 | Baseline PCA | 0.00 | 0.00 | 0.24 | 0.51 | 303.8 |
| **GTZAN** | **Conv-VAE** | **0.19** | **0.32** | **0.08** | **0.41** | **45.6** |
| GTZAN | Baseline PCA | 0.04 | 0.06 | -0.02 | 0.18 | 28.5 |

> **Note:** While PCA achieves higher Silhouette scores on HBLM due to dense acoustic clustering, it fails to capture the semantic (language) structure, resulting in ARI â‰ˆ 0.

<br>

## ğŸ“¥ Dataset Setup
Due to GitHub storage limits, raw audio files are not included. If running locally, please download them:

1.  **HBLM-100 (Custom):** [Download from Google Drive](https://drive.google.com/file/d/1YWjhcl6BYRUfViDYS_EltGRrTz6AxdyS/view?usp=sharing) and extract to `data/HBLM-100/audio/`.
2.  **GTZAN (Benchmark):** [Download from Kaggle](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) and extract to `data/GTZAN/`.

<br>

## ğŸ› ï¸ Installation (Local)
To run the code on your own machine:

```bash
git clone [https://github.com/rummanprodhan/Hybrid-Beta-VAE-Music-Clustering.git](https://github.com/rummanprodhan/Hybrid-Beta-VAE-Music-Clustering.git)
cd Hybrid-Beta-VAE-Music-Clustering
pip install -r requirements.txt


## ğŸ“‚ Repository Structure

```text
Hybrid-Beta-VAE-Music-Clustering/
â”‚
â”œâ”€â”€ data/                      # Dataset documentation
â”‚   â”œâ”€â”€ HBLM-100/              # Custom Dataset (Metadata included, Audio linked)
â”‚   â””â”€â”€ GTZAN/                 # Benchmark Dataset (Readme included)
â”‚
â”œâ”€â”€ notebooks/                 # Experiment Notebooks
â”‚   â”œâ”€â”€ 1_Hybrid_Beta_VAE_HBLM.ipynb      # Main Experiment (Bangla vs English)
â”‚   â””â”€â”€ 2_GTZAN_Benchmark_Clustering.ipynb # Generalization Benchmark
â”‚
â”œâ”€â”€ results/                   # Generated Plots & Visualizations
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ Disentangling_Language_and_Genre__Unsupervised_Cross_Cultural_Music_Clustering_via_Hybrid_Beta_VAE.pdf  # Final Scientific Report
â””â”€â”€ README.md                  # This file
